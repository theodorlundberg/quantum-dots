{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to useful functions for reflectometry measurements of quantum dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Theodor Lundberg, February 2021\n",
    " \n",
    "Note that the examples within do not run as-is because they rely on connection to an existing qcodes database and to instances of instruments in an experimental setup. The code must therefore be adjusted slightly such that is connects to your database and to your instruments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard useful libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from lmfit import Model\n",
    "\n",
    "# Import qcodes\n",
    "import qcodes as qc\n",
    "from qcodes import Station, load_or_create_experiment, \\\n",
    "    initialise_database, Measurement, load_by_run_spec, load_by_guid, initialise_or_create_database_at\n",
    "from qcodes.instrument.base import find_or_create_instrument\n",
    "from qcodes import load_last_experiment, load_experiment, new_experiment, experiments\n",
    "from qcodes.dataset.plotting import plot_dataset, plot_by_id\n",
    "from qcodes.logger.logger import start_all_logging\n",
    "import qcodes.instrument_drivers\n",
    "import qcodes.utils.validators as qcValidator\n",
    "\n",
    "# Import useful functions\n",
    "from functions.doNd_wSubplot import do0d, do1d, do2d, subplot_by_id_2, subplot_by_id_3, subplot_by_id_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions we introduce later, will require the qcodes experiment instance, and therefore we show how this can be defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "initialise_or_create_database_at(os.path.join(cwd, 'theosQCodesData.db'))\n",
    "qc.config[\"core\"][\"db_location\"] = os.path.join(cwd, 'theosQCodesData.db')\n",
    "exp = load_or_create_experiment(experiment_name='20200731 - DQD', sample_name=\"3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimising reflectometry signal as a function of magnetic field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dispersive readout with superconducting inductors, applying a magnetic field leads to increased kinetic inductance and hence smaller resonance frequencies. To retain the optimal readout signal, the probe frequency must therefore be updated as a function of magnetic field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Load a table where one can look up the reflectomtry resonance frequency of the resonator at a given magnetic field\n",
    "\n",
    "IMPORTANT: \n",
    "The look-up array should have B field values in 1st column and corresponding approximate drive frequencies in 2nd column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "filename = os.path.join(cwd, 'resonance_data', 'device_f_vs_B.csv')\n",
    "BtoF = np.loadtxt(filename, delimiter = '\\t',skiprows=1)\n",
    "filename_exp = os.path.join(cwd, 'resonance_data', 'device_f_vs_B_exp.csv')\n",
    "BtoF_exp = np.loadtxt(filename, delimiter = '\\t',skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create instances of relevant instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Magnet\n",
    "#By = find_or_create_instrument()\n",
    "\n",
    "#RF Source for reflectometry\n",
    "#RFSource = find_or_create_instrument()  \n",
    "\n",
    "# Oscilloscope for reflectometry\n",
    "#lcr = find_or_create_instrument() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateBtoFexp(B,rf):\n",
    "    '''\n",
    "    Updates and saves experimentally found optimal drive frequency.\n",
    "    '''\n",
    "    filename_exp = os.path.join(cwd, 'resonance_data', 'device_f_vs_B_exp.csv')\n",
    "    BtoF_exp = np.loadtxt(filename, delimiter = '\\t',skiprows=1)\n",
    "    \n",
    "    BmatchFound = False\n",
    "    for idx, BandFpair in enumerate(BtoF_exp):\n",
    "        if np.allclose(BandFpair[0],B): # update F for relevant B\n",
    "            BtoF_exp[idx][1] = rf\n",
    "            BmatchFound = True\n",
    "    \n",
    "    if not BmatchFound: # append new B,F pair\n",
    "        BtoF_exp = np.concatenate((BtoF_exp,np.array([[B,rf]])))\n",
    "    \n",
    "    pd.DataFrame(BtoF_exp, columns= ['B (T)','freq (Hz)']).to_csv(filename_exp, index=False, sep='\\t')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SignalOpt(aveSigOpt = 50, waitTime = 2):\n",
    "    '''\n",
    "    SignalOpt optimises a reflectometry signal for maximum phase response by varying the drive frequency. \n",
    "    \n",
    "    IMPORTANT: \n",
    "        A look-up array with B field values in 1st column and corresponding approximate drive frequencies in 2nd column \n",
    "        must be defined under the name BtoF before running the function. \n",
    "    \n",
    "    Args:\n",
    "        aveSigOpt: Number of oscilloscope trace averages used when measuring the signal being optimised\n",
    "        waitTime:  Number of seconds between setting new drive frequency and oscilloscope trace measurement\n",
    "    '''\n",
    "    #Check if the magnetic field is ramping. If it is, wait, if not, get B value \n",
    "    #which is used to look up the appropriate drive frequency\n",
    "    while True:\n",
    "        if By.ramping_state() == 'holding':\n",
    "            B = By.field()\n",
    "            B = np.abs(round(B*1000)/1000)\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "    print(\"Magnetic Field = %s T\" % (round(B*1000)/1000))\n",
    "    \n",
    "    #Initialise the signal optimisation variable and save current avering\n",
    "    maxx = 0\n",
    "    averaging = lcr.reflectometry.average()\n",
    "    \n",
    "    i = np.array(np.nonzero(BtoF[:,0] > B)).flat[0]    #Go trough look-up of B and drive frequency values\n",
    "    if abs(BtoF[i,0] - B) < abs(BtoF[i-1,0] - B):\n",
    "        closest = i                                  #Select the entry with closest match to B field\n",
    "    else:\n",
    "        closest = i-1\n",
    "    rf = BtoF[closest, 1]    #Choose the matching drive frequency, rf\n",
    "    \n",
    "    #for entry in BtoF:                                      #Go trough look-up of B and drive frequency values\n",
    "    #    if (abs(entry[0]-B)) <= 0.011:                        #Select the entry with closest match to B field\n",
    "    #        rf = entry[1]                                   #Choose the matching drive frequency, rf\n",
    "            \n",
    "    #Step through a frequency range of rf +/- 5MHz, save maximum phase response and reassign drive frequency\n",
    "    for f in np.arange(rf-5e6,rf+5e6,5e5):          \n",
    "        RFSource.freq(f/1000000)\n",
    "        time.sleep(waitTime)\n",
    "        lcr.reflectometry.average(aveSigOpt)\n",
    "        data = lcr.reflectometry.curvedata.get()\n",
    "        #tempMax = np.amax(abs(np.subtract(data[3], 45)))\n",
    "        tempMax = np.amax(np.subtract(data[3], 45))\n",
    "        if tempMax > maxx:\n",
    "            #Print when a new signal maximum is found and indicate the accompanying drive frequency\n",
    "            print(\"New signal max of %s degree shift found at %s MHz\" % (round(tempMax*1000)/1000,f/1e6))\n",
    "            maxx = tempMax                           #Redefine max phase response\n",
    "            rf = f                                   #Redefine rf to the rough signal optimisation value\n",
    "\n",
    "    #Step through a frequency range of newly optimised rf +/- 0.5MHz in finer steps and reassign drive frequency\n",
    "    for f in np.arange(rf-4e5,rf+5e5,1e5):\n",
    "        RFSource.freq(f/1000000)\n",
    "        time.sleep(waitTime)                \n",
    "        lcr.reflectometry.average(aveSigOpt)\n",
    "        data = lcr.reflectometry.curvedata.get()\n",
    "        #tempMax = np.amax(abs(np.subtract(data[3], 45)))\n",
    "        tempMax = np.amax(np.subtract(data[3], 45))\n",
    "        if tempMax > maxx:\n",
    "            #Print when a new signal maximum is found and indicate the accompanying drive frequency\n",
    "            print(\"New signal max of %s degree shift found at %s MHz\" % (round(tempMax*1000)/1000,f/1e6))\n",
    "            maxx = tempMax                           #Redefine max phase response\n",
    "            rf = f                                   #Redefine rf to the rough signal optimisation value\n",
    "    \n",
    "    #Signal now optimised. Optimised drive frequency printed and sent to RF source.\n",
    "    print(\"The optimal drive frequency at %s T is %s MHz\" % (B,rf/1e6))                \n",
    "    RFSource.freq(rf/1000000)\n",
    "    lcr.reflectometry.average(averaging)\n",
    "    \n",
    "    # Update and save experimentally optimal drive frequency\n",
    "    updateBtoFexp(B,rf)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FastSignalOpt():\n",
    "    '''\n",
    "    Optimises reflectometry signal by look-up into previously optimised f vs B only.\n",
    "    '''\n",
    "    while True:\n",
    "        if By.ramping_state() == 'holding':\n",
    "            B = By.field()\n",
    "            B = np.abs(round(B*1000)/1000)\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "    \n",
    "    i = np.array(np.nonzero(BtoF_exp[:,0] > B)).flat[0]    #Go trough look-up of B and drive frequency values\n",
    "    if abs(BtoF_exp[i,0] - B) < abs(BtoF_exp[i-1,0] - B):\n",
    "        closest = i                                  #Select the entry with closest match to B field\n",
    "    else:\n",
    "        closest = i-1\n",
    "    rf = BtoF_exp[closest, 1]  \n",
    "    \n",
    "    print(round(rf)/1000000)\n",
    "    RFSource.freq(round(rf)/1000000)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use functions\n",
    "Run the function before a measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SignalOpt()\n",
    "dataid, ax, cbax = do0d(exp, lcr.reflectometry.curvedata, name = 'name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or before each inner loop if e.g. doing a 2D measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataid, ax, cbax = do1d(exp, By.field, 0, 0.9, 46, 0.01, lcr.reflectometry.curvedata, before_inner_actions = (SignalOpt, ), name = 'name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for finding and storing interdot charge transition (ICT) centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found no file with the name device_name.csv! An empty dictionary has been prepared in stead.\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "from lmfit import Model\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "# Load or make ICT dictionary for storing coordinates and dimensions of ICT\n",
    "from functions.ICTDictionary import Dictionary\n",
    "ICTDict = Dictionary('device_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily add an ICT to the dictionary as a test using format for the voltages (G1_centre, G1_length, G2_centre, G2_length):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICT (2, 0) has been successfully added to the device_name dictionary with values (1, 0.04, 2, 0.05)\n"
     ]
    }
   ],
   "source": [
    "ICTDict.addICT((2,0),(1,0.04,2,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a bunch on functions that allow us to find the coordinates and size of an ICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### CUSTOM ERRORS #######################################\n",
    "class VoltageRangeError(ValueError):\n",
    "    \"\"\"Exception raised for errors in the input.\"\"\"\n",
    "    \n",
    "class BackgroundNoiseError(ValueError):\n",
    "    \"\"\"Exception raised for errors in the input.\"\"\"\n",
    "    \n",
    "class SwitchError(RuntimeError):\n",
    "    \"\"\"Exception raised for errors in the input.\"\"\"\n",
    "\n",
    "####################################### MODELS #######################################\n",
    "def gaussian(x, amp, cen, wid, offset):\n",
    "    return amp * np.exp(-(x-cen)**2 / (2*wid**2)) + offset\n",
    "\n",
    "def linear(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "def mexicanhat(x, amp, cen, wid, offset):\n",
    "    # for fitting phase data\n",
    "    t = x - cen\n",
    "    hat = 1 - ((t/wid)**2)\n",
    "    return (hat*gaussian(x, amp, cen, wid, 0)) + offset\n",
    "\n",
    "####################################### MODEL FITTERS #######################################\n",
    "def hist_gaussian_fitter(z, z_type, nbins = 200, verbose = False):\n",
    "    hist, binedges = np.histogram(z, bins = nbins)\n",
    "    bincentres = binedges + (binedges[1]-binedges[0])/2\n",
    "    bincentres = bincentres[:nbins]\n",
    "    model = Model(gaussian)\n",
    "    model.set_param_hint('offset', value=0, min=-1e-10, max=1e-10)        \n",
    "    model.set_param_hint('amp', value=np.amax(hist))  \n",
    "    model.set_param_hint('cen', value=bincentres[np.argmax(hist)])\n",
    "    model.set_param_hint('wid', value=(bincentres[-1]-bincentres[0])/20)\n",
    "    fit = model.fit(hist, x=bincentres)\n",
    "    \n",
    "    if verbose:\n",
    "        print(fit.fit_report())\n",
    "        plt.figure()\n",
    "        plt.plot(bincentres, hist)\n",
    "        plt.plot(bincentres, fit.init_fit, 'k--', label='initial fit')\n",
    "        plt.plot(bincentres, fit.best_fit, 'r-', label='best fit')\n",
    "        z_legend = ['I (V)','Q (V)','Magnitude (V)','Phase (deg)']\n",
    "        plt.xlabel(z_legend[z_type])\n",
    "        plt.ylabel('Histogram frequency with {0} bins'.format(nbins))\n",
    "        plt.legend()\n",
    "    return fit\n",
    "\n",
    "def linear_fitter(x, y, weights = None):\n",
    "    model = Model(linear)\n",
    "    a_est = (y[-1]-y[0])/(x[-1]-x[0])\n",
    "    b_est = y[0] - a_est*x[0]\n",
    "    model.set_param_hint('a', value=a_est)        \n",
    "    model.set_param_hint('b', value=b_est)   \n",
    "    fit = model.fit(y, x=x, weights=weights)\n",
    "    return fit\n",
    "\n",
    "def mexicanhatfitter(trace_x, trace_y):\n",
    "    # fits mexican hat func. to 1D voltage sweep across a charge transition. Works well on phase data.\n",
    "    # 'trace' is a 1-dimensional np.array \n",
    "    # returns lmfit Model result object\n",
    "    \n",
    "    gmodel = Model(mexicanhat)\n",
    "    xrange = np.abs(trace_x[-1] - trace_x[0])\n",
    "    \n",
    "    baseline = np.mean(trace_y)\n",
    "    peakIdx = np.argmax(np.abs(trace_y - baseline))\n",
    "    cen_est = trace_x[peakIdx]                          # take most distant point from mean as estimate for peak centre\n",
    "    halfamp = np.abs(trace_y[peakIdx] - baseline)/2\n",
    "    \n",
    "    # detect if peak is maximum or minimum - important for setting bounds on fit params\n",
    "    if (trace_y[peakIdx] - baseline) > 0:\n",
    "        # peak is a maximum\n",
    "        # estimate width - essential as ICT can be much thinner than DTL\n",
    "        halfmax = baseline + halfamp\n",
    "        try:\n",
    "            Redge = np.array(np.where((trace_y[peakIdx:-1] - halfmax) < 0))[0][0]\n",
    "            Ledge = np.array(np.where(np.flip(trace_y[0:peakIdx], axis=0) - halfmax < 0))[0][0]  # flip() used to count away from peak\n",
    "            wid_est = ((Redge + Ledge)/len(trace_x))*xrange\n",
    "        except:\n",
    "            # width estimation sometimes breaks, especially if peak too close to edge of trace. Measurements shouldn't stop if this happens\n",
    "            wid_est = 0.1*xrange\n",
    "        \n",
    "        amp_est = trace_y[peakIdx] - np.amin(trace_y)    # estimate amplitude\n",
    "        gmodel.set_param_hint('offset', value=baseline, min=-np.inf, max=baseline)\n",
    "        \n",
    "    else:\n",
    "        # peak is a minimum\n",
    "        halfmin = baseline - halfamp\n",
    "        try:\n",
    "            Redge = np.array(np.where((trace_y[peakIdx:-1] - halfmin) > 0))[0][0]\n",
    "            Ledge = np.array(np.where(np.flip(trace_y[0:peakIdx], axis=0) - halfmin > 0))[0][0]\n",
    "            wid_est = ((Redge + Ledge)/len(trace_x))*xrange\n",
    "        except:\n",
    "            wid_est = 0.1*xrange\n",
    "        \n",
    "        amp_est = trace_y[peakIdx] - np.amax(trace_y)\n",
    "        gmodel.set_param_hint('offset', value=baseline, min=baseline, max=np.inf)\n",
    "        \n",
    "    gmodel.set_param_hint('amp', value=amp_est, min=0, max=amp_est)    # beware hard-coded max and min assumptions!\n",
    "    gmodel.set_param_hint('cen', value=cen_est, min=cen_est-0.2*xrange, max=cen_est+0.2*xrange)\n",
    "    gmodel.set_param_hint('wid', value=wid_est, min=0, max=0.5*xrange)\n",
    "    \n",
    "    result = gmodel.fit(trace_y, x=trace_x)\n",
    "    return result\n",
    "\n",
    "####################################### DATA IMPORT #######################################\n",
    "def load_least_noisy_data(exp, run_id = None, stds = 3, verbose = False):\n",
    "    '''\n",
    "    Loads the least noisy data type (I, Q, Magnitude, or Phase) and returns the x, y, z and data type.\n",
    "    \n",
    "    params\n",
    "    ------\n",
    "    exp: qcodes experiment instance\n",
    "    run_id: measurement id to load\n",
    "    stds: threshold for determining least noisy data\n",
    "    '''\n",
    "    if run_id == None:\n",
    "        run_id = exp.last_counter\n",
    "    data = exp.data_set(run_id).get_parameter_data()\n",
    "    \n",
    "    ###################################################################################\n",
    "    ## ----------------------------------------------------------------------------- ##\n",
    "    ## IMPORTANT: LOADING DATA DEPENDS ON YOUR DATASTRUCTURE IN THE AQUIRED DATA !!! ##\n",
    "    ## ----------------------------------------------------------------------------- ##\n",
    "    ###################################################################################\n",
    "    \n",
    "    x = data['I']['G1_volt']\n",
    "    y = data['I']['LCR_Reflectometry_Sweep']\n",
    "    z_I = data['I']['I']\n",
    "    z_Q = data['Q']['Q']\n",
    "    z_M = data['magnitude']['magnitude']\n",
    "    z_P = data['phase']['phase']\n",
    "    z = [z_I, z_Q, z_M, z_P]\n",
    "    z_legend = ['I','Q','Magnitude','Phase']\n",
    "    \n",
    "    try:\n",
    "        x_thresholded_I,_,_ = threshold(x, y, z_I, 0, stds = stds, verbose = verbose)\n",
    "    except:\n",
    "        x_thresholded_I = np.array([])\n",
    "    \n",
    "    try:\n",
    "        x_thresholded_Q,_,_ = threshold(x, y, z_Q, 1, stds = stds, verbose = verbose)\n",
    "    except:\n",
    "        x_thresholded_Q = np.array([])\n",
    "        \n",
    "    try:\n",
    "        x_thresholded_M,_,_ = threshold(x, y, z_M, 2, stds = stds, verbose = verbose)\n",
    "    except:\n",
    "        x_thresholded_M = np.array([])\n",
    "        \n",
    "    try:\n",
    "        x_thresholded_P,_,_ = threshold(x, y, z_P, 3, stds = stds, verbose = verbose)\n",
    "    except:\n",
    "        x_thresholded_P = np.array([])\n",
    "    \n",
    "    i = np.argmax([x_thresholded_I.shape[0],x_thresholded_Q.shape[0],x_thresholded_M.shape[0],x_thresholded_P.shape[0]])\n",
    "    \n",
    "    print('The least noisy data (' + z_legend[i] + ') has been successfully loaded')\n",
    "    return x, y, z[i], i\n",
    "\n",
    "####################################### FIND ICT FUNCTIONS #######################################\n",
    "def get_ict(x, y, z, z_type, stds, verbose = False):\n",
    "    '''\n",
    "    Finds and returns the coordinates of the ICT in the x, y, z data. \n",
    "    \n",
    "    params\n",
    "    ------\n",
    "    x: array with x values (gate 1)\n",
    "    y: array with y values (gate 2)\n",
    "    z: array of dimension x by y with reflectometry data\n",
    "    z_type: int with mapping 0: I, 1: Q, 2: Mag, 3: Phase\n",
    "    stds: float indicating where to threshold the data (large value = less data is removed). stds=6 may be a good starting point.\n",
    "    ''' \n",
    "    n_traces = x.shape[0]/6000\n",
    "    \n",
    "    threshold_trace_ratio = 0\n",
    "    while threshold_trace_ratio < 0.80: # require that thresholding leaves 80% of the traces intact     \n",
    "        try:\n",
    "            # remove all data below threshold\n",
    "            x_thresholded_nozeros, y_thresholded_nozeros, z_thresholded_norm_nozeros = threshold(x, y, z, z_type, stds = stds, verbose = verbose)\n",
    "\n",
    "            # take the mean for each trace (one trace may have several point outside of the threshold)\n",
    "            x_transition, y_transition = trace_mean(x_thresholded_nozeros, y_thresholded_nozeros, weights = z_thresholded_norm_nozeros)\n",
    "            \n",
    "            threshold_trace_ratio = x_transition.shape[0]/n_traces\n",
    "            stds -= 0.5\n",
    "        except ValueError:\n",
    "            raise BackgroundNoiseError('When removing gaussian noise from the data, there is no data left after thresholding!')\n",
    "        except SwitchError:\n",
    "            raise SwitchError('A switch seems to have occured in the measurement!')\n",
    "    \n",
    "    switchbool = check_for_switch(x_transition, y_transition, z_type, stds = 8, verbose = verbose)\n",
    "    if switchbool:\n",
    "        raise SwitchError('A switch seems to have occured in the measurement!')        \n",
    "\n",
    "    # get the index position of the triple points\n",
    "    tp_args, x_transition, y_transition, x_outliers_removed, y_outliers_removed, z_norm_outliers_removed = get_triple_point_args(x_thresholded_nozeros, y_thresholded_nozeros, weights = z_thresholded_norm_nozeros, verbose = verbose)\n",
    "    \n",
    "    # determine ict dimensions\n",
    "    tp_1 = (x_transition[tp_args[0]], y_transition[tp_args[0]])\n",
    "    tp_2 = (x_transition[tp_args[1]], y_transition[tp_args[1]])\n",
    "    ict_centre = ((tp_1[0]+tp_2[0])/2,(tp_1[1]+tp_2[1])/2)\n",
    "    ict_y_length = tp_2[1]-tp_1[1]\n",
    "    ict_x_length = tp_2[0]-tp_1[0]\n",
    "    \n",
    "    # prepare colour and transparency for threshold data\n",
    "    rgba_colors_outliers_removed = np.zeros((z_norm_outliers_removed.shape[0],4))\n",
    "    rgba_colors_outliers_removed[:, 2] = 1.0\n",
    "    rgba_colors_outliers_removed[:, 3] = z_norm_outliers_removed\n",
    "    \n",
    "    # plot transition, triple points and ict centre\n",
    "    plt.figure()\n",
    "    plt.scatter(x_outliers_removed, y_outliers_removed, s = 2, color=rgba_colors_outliers_removed, label = 'Thresholded data')\n",
    "    plt.plot(x_transition, y_transition, 'tab:orange', label = ' Transition mean')\n",
    "    plt.xlim([np.amin(x_outliers_removed),np.amax(x_outliers_removed)])\n",
    "    plt.ylim([np.amin(y_outliers_removed),np.amax(y_outliers_removed)])\n",
    "    plt.scatter([tp_1[0],tp_2[0]], [tp_1[1],tp_2[1]], c = 'r', label = 'Estimated triple points')\n",
    "    plt.scatter(ict_centre[0], ict_centre[1], c = 'g', label = 'Estimated ICT centre')\n",
    "    plt.xlabel('Step voltage (V)')\n",
    "    plt.ylabel('Sweep voltage (V)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ###################### Get name and location for figure ######################\n",
    "    cwd = os.getcwd()\n",
    "    name = os.path.join(cwd, exp.name, exp.sample_name, 'png', str(exp.last_data_set().run_id)+'_findICTcentre.png')\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "    \n",
    "    # (G1_centre, G1_length, G2_centre, G2_length)\n",
    "    return (round(ict_centre[0]*1e8)/1e8, round(ict_x_length*1e8)/1e8, round(ict_centre[1]*1e8)/1e8, round(ict_y_length*1e8)/1e8)\n",
    "\n",
    "def threshold(x, y, z, z_type, stds = 6, verbose = False):\n",
    "    '''\n",
    "    Thresholds 2D data\n",
    "    '''\n",
    "    gauss_fit = hist_gaussian_fitter(z, z_type, nbins = 200, verbose = verbose)\n",
    "    lower_threshold = gauss_fit.best_values['cen']-gauss_fit.best_values['wid']*stds\n",
    "    upper_threshold = gauss_fit.best_values['cen']+gauss_fit.best_values['wid']*stds\n",
    "    z_thresholded = np.where(z > upper_threshold, z, 0) + np.where(z < lower_threshold, z, 0)\n",
    "    z_thresholded_norm = normalise(z_thresholded)\n",
    "    \n",
    "    x_thresholded = np.where(z_thresholded > 0, x, 0)\n",
    "    y_thresholded = np.where(z_thresholded > 0, y, 0)\n",
    "    \n",
    "    z_thresholded_norm_nozeros = z_thresholded_norm[np.where(z_thresholded > 0)]\n",
    "    x_thresholded_nozeros = x_thresholded[np.where(x_thresholded > 0)]\n",
    "    y_thresholded_nozeros = y_thresholded[np.where(y_thresholded > 0)]\n",
    "    \n",
    "    if verbose:\n",
    "        plt.plot([gauss_fit.best_values['cen']+gauss_fit.best_values['wid']*stds, gauss_fit.best_values['cen']+gauss_fit.best_values['wid']*stds],[0,gauss_fit.best_values['amp']], 'tab:orange', label = 'threshold')\n",
    "        plt.legend()\n",
    "        \n",
    "    return x_thresholded_nozeros, y_thresholded_nozeros, z_thresholded_norm_nozeros\n",
    "\n",
    "def threshold_1d(x, y, y_type, stds = 6, verbose = False):\n",
    "    '''\n",
    "    Thresholds 1D data\n",
    "    '''\n",
    "    try:\n",
    "        gauss_fit = hist_gaussian_fitter(y, y_type, nbins = 200, verbose = verbose)\n",
    "        lower_threshold = gauss_fit.best_values['cen']-gauss_fit.best_values['wid']*stds\n",
    "        upper_threshold = gauss_fit.best_values['cen']+gauss_fit.best_values['wid']*stds\n",
    "        y_thresholded = np.where(y > upper_threshold, y, 0) + np.where(y < lower_threshold, y, 0)\n",
    "        y_thresholded_norm = normalise(y_thresholded)\n",
    "\n",
    "        x_thresholded = np.where(y_thresholded > 0, x, 0)\n",
    "\n",
    "        y_thresholded_norm_nozeros = y_thresholded_norm[np.where(y_thresholded > 0)]\n",
    "        x_thresholded_nozeros = x_thresholded[np.where(x_thresholded > 0)]\n",
    "\n",
    "        if verbose:\n",
    "            plt.plot([gauss_fit.best_values['cen']+gauss_fit.best_values['wid']*stds, gauss_fit.best_values['cen']+gauss_fit.best_values['wid']*stds],[0,gauss_fit.best_values['amp']], 'tab:orange', label = 'threshold')\n",
    "            plt.legend()\n",
    "\n",
    "        return x_thresholded_nozeros, y_thresholded_norm_nozeros\n",
    "    except:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "def get_triple_point_args(x, y, weights = None, verbose = False):\n",
    "    '''\n",
    "    Finds the triple points of the ICT\n",
    "    '''\n",
    "    success = False\n",
    "    n_outlier_removals = 0\n",
    "    while not success and n_outlier_removals < 20:\n",
    "        try:\n",
    "            x_transition, y_transition = trace_mean(x, y, weights = weights)\n",
    "            lin_fit = linear_fitter(x_transition, y_transition)\n",
    "            error_0 = linerror(y_transition, lin_fit.best_fit)\n",
    "\n",
    "            if verbose:\n",
    "                plt.figure()\n",
    "                plt.plot(x_transition, y_transition, '.')\n",
    "                plt.plot(x_transition, lin_fit.best_fit)\n",
    "                plt.plot(x_transition, y_transition, '.', label = 'Transition')\n",
    "                plt.plot(x_transition, lin_fit.init_fit, 'k--', label='initial fit')\n",
    "                plt.plot(x_transition, lin_fit.best_fit, 'r-', label='best fit')\n",
    "                plt.xlabel('Step voltage (V)')\n",
    "                plt.ylabel('Sweep voltage (V)')\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()                \n",
    "\n",
    "            error = error_0\n",
    "            num_extremas = 0\n",
    "            n_smooths = 0\n",
    "            while num_extremas != 2:\n",
    "                n_smooths += 1\n",
    "                if n_smooths > 8: # warning: n_smooths below three may cause low-SNR icts not to be identified\n",
    "                    raise VoltageRangeError('Voltage window in stepped voltage axis is too small or shifted too far from ICT centre')\n",
    "                window = np.max((len(lin_fit.best_fit)//40*2-1,3))\n",
    "                error = signal.savgol_filter(error, window, 1)\n",
    "                max_args = argrelextrema(error, np.greater)[0]\n",
    "                min_args = argrelextrema(error, np.less)[0]\n",
    "                num_extremas = max_args.shape[0] + min_args.shape[0]\n",
    "\n",
    "            if verbose:        \n",
    "                plt.figure()\n",
    "                plt.plot(x_transition, error_0, label = 'Unsmoothed error')\n",
    "                plt.plot(x_transition, error, label = 'Error smoothed {0} time(s)'.format(n_smooths))\n",
    "                plt.xlabel('Step voltage (V)')\n",
    "                plt.ylabel('Error from linear fit (V)')\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "            success = True\n",
    "            \n",
    "        except:\n",
    "            x, y, weights = remove_outliers_lin_fit(x, y, weights = weights, percent = 2, verbose = verbose)\n",
    "            n_outlier_removals += 1\n",
    "            if x.shape[0] < 50:\n",
    "                raise BackgroundNoiseError('When removing outliers from the data, there is not enough data left')\n",
    "\n",
    "            if verbose:        \n",
    "                plt.figure()\n",
    "                plt.plot(x_transition, error_0, label = 'Unsmoothed error')\n",
    "                plt.plot(x_transition, error, label = 'Error smoothed {0} time(s)'.format(n_smooths))\n",
    "                plt.xlabel('Step voltage (V)')\n",
    "                plt.ylabel('Error from linear fit (V)')\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    return np.concatenate((min_args, max_args)), x_transition, y_transition, x, y, weights\n",
    "\n",
    "def normalise(z):\n",
    "    non_zero_min = np.min(z[np.where(z > 0)])\n",
    "    z = np.where(z > 0, z - non_zero_min, z)\n",
    "    return z / np.amax(np.abs(z))\n",
    "\n",
    "def sqerror(t, t_model):\n",
    "    return (t-t_model)**2\n",
    "\n",
    "def linerror(t, t_model):\n",
    "    return (t-t_model)\n",
    "\n",
    "def trace_mean(x, y, weights = None):\n",
    "    prev_x = 0\n",
    "    x_no_replicas = []\n",
    "    y_mean = []\n",
    "    for curr_x in x:\n",
    "        if prev_x < curr_x:\n",
    "            if not (weights is None):\n",
    "                y_mean.append(np.average(y[np.where(x == curr_x)], weights = weights[np.where(x == curr_x)]))\n",
    "            else:\n",
    "                y_mean.append(np.mean(y[np.where(x == curr_x)]))\n",
    "            x_no_replicas.append(curr_x)\n",
    "            prev_x = curr_x\n",
    "\n",
    "    x_no_replicas = np.array(x_no_replicas)\n",
    "    y_mean = np.array(y_mean)\n",
    "    return x_no_replicas, y_mean\n",
    "\n",
    "def remove_outliers_lin_fit(x, y, weights = None, percent = 5, verbose = False):\n",
    "    '''\n",
    "    Removes a percentage of the data that is farthest from a linear fit to the data.\n",
    "    \n",
    "    params\n",
    "    ------\n",
    "    x: array with the x indexes of a transition\n",
    "    y: array with the y indexes of a transition\n",
    "    weights: array with the weighting of each data point\n",
    "    percent: float indicating how much of the data to remove\n",
    "    '''\n",
    "    lin_fit = linear_fitter(x, y, weights = weights)\n",
    "    error = sqerror(y, lin_fit.best_fit)\n",
    "    \n",
    "    sort_order = np.argsort(error)\n",
    "    percent_cut = np.int(np.round((1-percent/100)*x.shape[0]))\n",
    "    x_outliers_removed = x[sort_order][:percent_cut]\n",
    "    y_outliers_removed = y[sort_order][:percent_cut]\n",
    "    weigths_outliers_removed = weights[sort_order][:percent_cut]\n",
    "    \n",
    "    rev_sort_order = np.argsort(x_outliers_removed)\n",
    "    x_outliers_removed = x_outliers_removed[rev_sort_order]\n",
    "    y_outliers_removed = y_outliers_removed[rev_sort_order]\n",
    "    weigths_outliers_removed = weigths_outliers_removed[rev_sort_order]\n",
    "    \n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.plot(x, y, 'o', label = 'Before outlier removal')\n",
    "        plt.plot(x, lin_fit.best_fit, label = 'Linear fit for error calculation')\n",
    "        plt.plot(x_outliers_removed, y_outliers_removed, '.', label = 'After outlier removal')\n",
    "        plt.xlabel('Step voltage (V)')\n",
    "        plt.ylabel('Sweep voltage (V)')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    return x_outliers_removed, y_outliers_removed, weigths_outliers_removed\n",
    "\n",
    "\n",
    "def check_for_switch(x, y, y_type, stds = 8, verbose = False):\n",
    "    '''\n",
    "    Checks if there was a switch during the measurement of the ICT, as a switch may be mistaken as an ICT.\n",
    "    \n",
    "    params\n",
    "    ------\n",
    "    x: array with x data for transition\n",
    "    y: array with y data for transition\n",
    "    y_type: int with mapping 0: I, 1: Q, 2: Mag, 3: Phase\n",
    "    stds: float indicating where to threshold the data (large value = less data is removed).\n",
    "    '''\n",
    "    \n",
    "    y_dif = np.ones(y.shape[0]-1)\n",
    "    y_difdif = np.ones(y.shape[0]-2)\n",
    "\n",
    "    for i in range(y.shape[0]-1):\n",
    "        y_dif[i] = (y[i+1] - y[i])/(x[i+1] - x[i])\n",
    "\n",
    "    for i in range(y_dif.shape[0]-1):\n",
    "        y_difdif[i] = (y_dif[i+1] - y_dif[i])/(x[i+1] - x[i])\n",
    "\n",
    "    if verbose:\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('Step Voltage (V)')\n",
    "        ax1.set_ylabel('Slope of transition', color='tab:red')\n",
    "        ax1.plot(x[:-1], y_dif, '.', color='tab:red')\n",
    "        ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "        ax2 = ax1.twinx()  # create a second axes that shares the same x-axis\n",
    "        color = 'tab:blue'\n",
    "        ax2.set_ylabel('Curvature of transition', color='tab:blue')  # we already handled the x-label with ax1\n",
    "        ax2.plot(x[:-2], y_difdif, '.', color='tab:blue')\n",
    "        ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        plt.show()\n",
    "        \n",
    "        #plt.figure()\n",
    "        #plt.plot(x[:-1], y_dif, '.', label = 'Slope of transition')\n",
    "        ##plt.plot(x[:-2], y_difdif, '.', label = 'Curvature of transition')\n",
    "        #plt.xlabel('Step Voltage (V)')\n",
    "       # plt.legend()\n",
    "\n",
    "    x_switch, y_switch = threshold_1d(x[:-2], y_difdif, y_type, stds = stds, verbose = verbose)\n",
    "    x_switch2, y_switch2 = threshold_1d(x[:-2], -y_difdif, y_type, stds = stds, verbose = verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of points with abnormally large transition curvature: {0}'.format(x_switch.shape[0], x_switch2.shape[0]))\n",
    "\n",
    "    if (x_switch.shape[0] == x_switch2.shape[0] and x_switch.shape[0] == 1):\n",
    "        return True\n",
    "    else:\n",
    "        return False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we already have a measurement of an ICT, the key functions we need to find and save the coordinates and size are now just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ict = (2,1)\n",
    "last_id = exp.last_counter\n",
    "x, y, z, z_type = load_least_noisy_data(exp, run_id = last_id)\n",
    "centre = get_ict(x, y, z, z_type, stds = 6, verbose = verbose)\n",
    "ICTDict.addICT(ict, centre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is also useful to be able run just a simple function that both acquires a charge stability diagram measurement and finds the ICT. This is done below with the function findICTwrapped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_sweep_centre(ict_centre, data_index, verbose = False):\n",
    "    '''\n",
    "    Finetunes the centre position of the ICT on the sweep axis (corresponing the the gate with resonant circuit).\n",
    "    \n",
    "    params\n",
    "    ------\n",
    "    ict_centre : tuple (G1_centre, G1_length, G2_centre, G2_length)\n",
    "    data_index : int with mapping 0: I, 1: Q, 2: Mag, 3: Phase\n",
    "    '''\n",
    "    pre_ave = lcr.reflectometry.average()\n",
    "    pre_power = RFSource.power()\n",
    "    RFSource.power(10)\n",
    "    lcr.reflectometry.average(200)\n",
    "    \n",
    "    G2.volt(ICTDict.dict[ict]['G2_centre'])\n",
    "    G2.amp(5*ICTDict.dict[ict]['G2_length'])\n",
    "    G1.volt(ict_centre[0])\n",
    "    y = lcr.reflectometry.curvedata.get()    # get data\n",
    "    x = np.array(lcr.reflectometry.curvedata.calc_set_points()[0])    # get x-axis\n",
    "    \n",
    "    x_threshold, y_threshold = threshold_1d(x, y[data_index], data_index, stds = 3, verbose = verbose)\n",
    "    threshold_ratio = x_threshold.shape[0]/y[data_index].shape[0]\n",
    "    print('Ratio of thresholded data to total data in finetuning of fit: %.6f' % threshold_ratio)    \n",
    "    if threshold_ratio > 0.0002:\n",
    "        fit = mexicanhatfitter(x, y[data_index])\n",
    "        if verbose:\n",
    "            print(fit.fit_report())\n",
    "            plt.figure()\n",
    "            plt.plot(x, y[data_index])\n",
    "            plt.plot(x, fit.init_fit, 'k--', label='initial fit')\n",
    "            plt.plot(x, fit.best_fit, 'r-', label='best fit')\n",
    "            plt.legend()\n",
    "        \n",
    "        lcr.reflectometry.average(pre_ave)\n",
    "        RFSource.power(pre_power)\n",
    "        return (ict_centre[0], ict_centre[1], round(fit.best_values['cen']*1e8)/1e8, ict_centre[3])\n",
    "    \n",
    "    else:\n",
    "        lcr.reflectometry.average(pre_ave)\n",
    "        RFSource.power(pre_power)\n",
    "        return (ict_centre[0], ict_centre[1], ict_centre[2], ict_centre[3])\n",
    "    \n",
    "def findICTwrapped(ict, exp, verbose = False):\n",
    "    pre_ave = lcr.reflectometry.average()\n",
    "    pre_power = RFSource.power()\n",
    "    RFSource.power(10)\n",
    "    \n",
    "    setSweepGate(offset = ICTDict.dict[ict]['G2_centre']*4, amp = 2.5)\n",
    "    _ave_start = 25\n",
    "    _G1centre = ICTDict.dict[ict]['G1_centre']\n",
    "    _G1offset = 0.0075 ## HYPERPARAMETER FOR CHANGING WIDTH OF STEP GATE WINDOW IN SEARCH OF ICT\n",
    "    _n_traces = np.int(_G1offset*10000+1)\n",
    "    r = 1\n",
    "    s = 0\n",
    "    ICTfound = False\n",
    "    while not (r > 3 or s > 5 or ICTfound):\n",
    "        try:\n",
    "            # set voltages for stability diagram measurement\n",
    "            G1start = _G1centre-_G1offset*r\n",
    "            G1end = _G1centre+_G1offset*r\n",
    "            lcr.reflectometry.average(r*25)\n",
    "            # do charge stability diagram measurement\n",
    "            dataid, ax, cbax = do1d(exp, G1.volt, G1start, G1end, _n_traces*r, 0.01, lcr.reflectometry.curvedata, name = name)\n",
    "            plt.show()\n",
    "            \n",
    "            # update centre of ICT\n",
    "            last_id = exp.last_counter\n",
    "            x, y, z, z_type = load_least_noisy_data(exp, run_id = last_id)\n",
    "            centre = get_ict(x, y, z, z_type, stds = 6, verbose = verbose)\n",
    "            ICTfound = True\n",
    "            \n",
    "        except SwitchError:\n",
    "            print('A switch occured and was identified. Repeating measurement.')\n",
    "            s += 1\n",
    "            \n",
    "        except:\n",
    "            print('Measurement was too noisy or ICT was not inside measurement window. Expand measurement window and increase averaging for next measurement.')\n",
    "            r += 1\n",
    "            \n",
    "#       TO-DO\n",
    "#         finally:\n",
    "#             if not ICTfound:\n",
    "#                 send slack message\n",
    "    \n",
    "    RFSource.power(pre_power)\n",
    "    lcr.reflectometry.average(pre_ave)\n",
    "    \n",
    "    return centre, z_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a measurement and add ICT to dictionary, we just run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centre, _ = findICTwrapped(ict, exp, verbose = False)\n",
    "ICTDict.addICT(ict,centre_fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we want to update one or more ICT positions, we just run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update centre of ICT\n",
    "for ict in [(2,1)]:\n",
    "    centre, i = findICTwrapped(ict, exp, verbose = False)\n",
    "    centre_fine = finetune_sweep_centre(centre, i, verbose = False)\n",
    "    ICTDict.addICT(ict,centre_fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An updated ICT dictionary is incredibly useful, as you can loop through a subset of the ICTs in your dictionary and perform the same measurement on each ICT using the stored information in the dictionary. Example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voltage source for gate 1\n",
    "#G1 = find_or_create_instrument() \n",
    "\n",
    "# function generator for gate 2\n",
    "#G2 = find_or_create_instrument() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ict in [(1,1),(2,1),(1,2),(2,2)]:\n",
    "    # set voltages based on information about ICT coordinates\n",
    "    G1.volt(ICTDict.dict[ict]['G1_centre'])\n",
    "    G2.volt(ICTDict.dict[ict]['G2_centre'])\n",
    "    G2.amp(5*ICTDict.dict[ict]['G2_length'])\n",
    "    \n",
    "    # do measurement\n",
    "    dataid, ax, cbax = do1d(exp, By.field, 0, 0.9, 46, 0.01, lcr.reflectometry.curvedata, before_inner_actions = (SignalOpt, ), name = 'name')plt.show()\n",
    "    \n",
    "    # reset\n",
    "    By.field(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
